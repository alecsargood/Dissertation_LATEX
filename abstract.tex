\begin{abstract}

Gene expression time delays, arising from complex biological processes such as gene transcription and translation, have been shown to play an important role in cellular dynamics. Time delays, motivated by the gene expression process, can also greatly affect the behaviour of reaction-diffusion systems, and in this dissertation, we explore their effects on Turing pattern mechanisms. By incorporating time delays, modelled as both a fixed parameter and as a continuous distribution, into classical reaction-diffusion systems that exhibit Turing instabilities, we investigate the changing behaviour of these systems. We find that an introduction of increasing time delay increases the time taken for spatially inhomogeneous patterns to stabilise, and the two are related linearly. We also present results to show, through a linear stability analysis, that an increasing time delay can act both to expand or shrink the Turing space of a certain reaction-diffusion mechanism, depending on the placement of time-delayed terms. Significantly, we find that modelling time delays as a continuous distribution does not have a significant effect on the results seen compared with a fixed time delay. These findings serve to highlight the importance of considering gene expression time delays when modelling biological patterning events, as well as requiring a complete understanding of the cellular dynamics before attempting to apply Turing mechanisms to explain biological phenomena.

\end{abstract}
