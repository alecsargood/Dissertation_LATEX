\begin{abstract}

Gene expression time delays, modelling the complex biological processes of gene transcription and translation, have been shown to play an important role in cellular dynamics. Time delays, motivated by the gene expression process, can also greatly affect the behaviour of reaction-diffusion systems. In this dissertation, we explore their effects on Turing pattern mechanisms. By incorporating time delays, modelled as both a fixed parameter and as a continuous distribution, into classical reaction-diffusion systems that exhibit Turing instabilities, we investigate the changing behaviour of these systems. We find that an introduction of increasing time delay increases the time taken for spatially inhomogeneous patterns to stabilise, and the two are related linearly. We also present results to show, through a linear stability analysis, that an increasing time delay can act both to expand or shrink the Turing space of a certain reaction-diffusion mechanism, depending on the placement of time-delayed terms. Significantly, we find that modelling time delays as a continuous distribution has a negligible impact on qualitative or quantitative aspects of the results seen compared with a fixed time delay of the mean of the distribution. These findings serve to highlight the importance of considering gene expression time delays when modelling biological patterning events, as well as requiring a complete understanding of the cellular dynamics before attempting to apply Turing mechanisms to explain biological phenomena. The results also suggest, at least for the distributions considered in this dissertation, that fixed delay and distributed delay models have almost identical dynamics. This allows one to use simpler fixed delay models rather than the more complicated distributed delay variants.

\end{abstract}
